{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fase 3b: Deep Learning Models (BiLSTM)\n",
                "\n",
                "En este notebook, usamos `Word2Vec` para entrenar embeddings y `BiLSTM` para la clasificación."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\otero\\Documents\\PKM\\200 - BEREICHE - AREAS\\UNIVERSITÄT - Universidad\\UTAMED\\PLN\\raa\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Add src\n",
                "sys.path.append(os.path.abspath(\"../src\"))\n",
                "from dl_models import AdvancedDLManager"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Indices fijados -> Train Total: 72679, Test Intocable: 18170\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\otero\\AppData\\Local\\Temp\\ipykernel_13232\\2587131664.py:2: DtypeWarning: Columns (0,1,5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  df_full = pd.read_csv(data_path)\n"
                    ]
                }
            ],
            "source": [
                "data_path = Path(\"../data/processed_corpus.csv\")\n",
                "df_full = pd.read_csv(data_path)\n",
                "df_full = df_full.dropna(subset=['clean_text', 'sentiment_score'])\n",
                "\n",
                "# Definimos columnas a probar\n",
                "input_columns = ['clean_text', 'lemmas_text']\n",
                "\n",
                "# Usamos clean_text solo para sacar los índices, luego usaremos la columna que toque\n",
                "X_indices = df_full['clean_text'] \n",
                "y = df_full['sentiment_score']\n",
                "\n",
                "# Test \n",
                "X_train_raw, X_test_real, y_train_raw, y_test_real = train_test_split(\n",
                "    X_indices, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "train_idx = X_train_raw.index\n",
                "test_idx = X_test_real.index\n",
                "\n",
                "print(f\"Indices fijados -> Train Total: {len(train_idx)}, Test Intocable: {len(test_idx)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Entrenamiento de modelos de deep learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "experiments_config = [\n",
                "    {\n",
                "        'name': 'Baseline: Word2Vec + BiLSTM',\n",
                "        'strategy': 'w2v',\n",
                "        'model': None\n",
                "    },\n",
                "    {\n",
                "        'name': 'SOTA: All-MiniLM + MLP',\n",
                "        'strategy': 'transformer',\n",
                "        'model': 'sentence-transformers/all-MiniLM-L6-v2' \n",
                "    },\n",
                "    {\n",
                "        'name': 'SOTA: BGE-Small + MLP',\n",
                "        'strategy': 'transformer',\n",
                "        'model': 'BAAI/bge-small-en-v1.5'\n",
                "    },\n",
                "    {\n",
                "        'name': 'GenAI: Gemma-Embed + MLP',\n",
                "        'strategy': 'ollama',\n",
                "        'model': 'embeddinggemma:latest'\n",
                "    }\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "============================================================\n",
                        ">>> PROCESANDO FEATURE: CLEAN_TEXT <<<\n",
                        "============================================================\n",
                        "Balanceando Train a 3898 muestras por clase...\n",
                        "   Datos Finales DL -> Train: 10524, Val: 1170\n",
                        "\n",
                        "   >>> Entrenando: Baseline: Word2Vec + BiLSTM (clean_text)\n",
                        "Estrategia: w2v | Dimensión Vectores: 100\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\otero\\AppData\\Local\\Temp\\ipykernel_13232\\3124149549.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
                        "  balanced_train = train_df_temp.groupby('target').apply(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando BiLSTM en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:04<00:00, 72.24it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.5649 - Val Acc: 0.7547\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:04<00:00, 75.43it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.5137 - Val Acc: 0.7547\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:04<00:00, 77.14it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.5061 - Val Acc: 0.7675\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:04<00:00, 76.16it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.4972 - Val Acc: 0.7504\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:04<00:00, 76.88it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.4935 - Val Acc: 0.7761\n",
                        "      Evaluando en Test Set...\n",
                        "RESULTADO: accuracy                           0.91     18170 | macro avg       0.66      0.76      0.69     18170\n",
                        "\n",
                        "   >>> Entrenando: SOTA: All-MiniLM + MLP (clean_text)\n",
                        "Cargando Sentence Transformer: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Estrategia: transformer | Dimensión Vectores: 384\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 329/329 [00:05<00:00, 62.96it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 37/37 [00:00<00:00, 66.03it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando SemanticMLP en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:01<00:00, 289.48it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.4817 - Val Acc: 0.8068\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:01<00:00, 289.23it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.4072 - Val Acc: 0.8068\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:01<00:00, 281.02it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.3836 - Val Acc: 0.8197\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:01<00:00, 271.40it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.3565 - Val Acc: 0.8128\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:01<00:00, 256.10it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.3327 - Val Acc: 0.8051\n",
                        "      Evaluando en Test Set...\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 568/568 [00:05<00:00, 99.06it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RESULTADO: accuracy                           0.92     18170 | macro avg       0.69      0.81      0.73     18170\n",
                        "\n",
                        "   >>> Entrenando: SOTA: BGE-Small + MLP (clean_text)\n",
                        "Cargando Sentence Transformer: BAAI/bge-small-en-v1.5\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\otero\\Documents\\PKM\\200 - BEREICHE - AREAS\\UNIVERSITÄT - Universidad\\UTAMED\\PLN\\raa\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\otero\\.cache\\huggingface\\hub\\models--BAAI--bge-small-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
                        "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
                        "  warnings.warn(message)\n",
                        "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Estrategia: transformer | Dimensión Vectores: 384\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 329/329 [00:08<00:00, 36.89it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 37/37 [00:01<00:00, 31.48it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando SemanticMLP en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:01<00:00, 289.80it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.4148 - Val Acc: 0.8419\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:01<00:00, 292.46it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.3434 - Val Acc: 0.8342\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:01<00:00, 282.05it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.3134 - Val Acc: 0.8453\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:01<00:00, 281.91it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.2864 - Val Acc: 0.8479\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:01<00:00, 271.80it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.2639 - Val Acc: 0.8470\n",
                        "      Evaluando en Test Set...\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 568/568 [00:09<00:00, 57.36it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RESULTADO: accuracy                           0.93     18170 | macro avg       0.73      0.85      0.77     18170\n",
                        "\n",
                        "   >>> Entrenando: GenAI: Gemma-Embed + MLP (clean_text)\n",
                        "Conectando a Ollama: embeddinggemma:latest\n",
                        "Estrategia: ollama | Dimensión Vectores: 768\n",
                        "Pre-computando embeddings (ollama)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ollama Embedding: 100%|██████████| 10524/10524 [21:31<00:00,  8.15it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pre-computando embeddings (ollama)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ollama Embedding: 100%|██████████| 1170/1170 [02:23<00:00,  8.16it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando SemanticMLP en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:01<00:00, 252.86it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.3560 - Val Acc: 0.8684\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:01<00:00, 251.49it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.2901 - Val Acc: 0.8855\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:01<00:00, 246.40it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.2562 - Val Acc: 0.8829\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:01<00:00, 239.62it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.2267 - Val Acc: 0.8838\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:01<00:00, 254.53it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.2045 - Val Acc: 0.8632\n",
                        "      Evaluando en Test Set...\n",
                        "Pre-computando embeddings (ollama)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ollama Embedding: 100%|██████████| 18170/18170 [37:35<00:00,  8.05it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RESULTADO: accuracy                           0.95     18170 | macro avg       0.77      0.86      0.81     18170\n",
                        "\n",
                        "============================================================\n",
                        ">>> PROCESANDO FEATURE: LEMMAS_TEXT <<<\n",
                        "============================================================\n",
                        "Balanceando Train a 3898 muestras por clase...\n",
                        "   Datos Finales DL -> Train: 10524, Val: 1170\n",
                        "\n",
                        "   >>> Entrenando: Baseline: Word2Vec + BiLSTM (lemmas_text)\n",
                        "Estrategia: w2v | Dimensión Vectores: 100\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\otero\\AppData\\Local\\Temp\\ipykernel_13232\\3124149549.py:22: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
                        "  balanced_train = train_df_temp.groupby('target').apply(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando BiLSTM en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:05<00:00, 59.56it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.5660 - Val Acc: 0.7444\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:04<00:00, 70.50it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.5290 - Val Acc: 0.7581\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:04<00:00, 67.50it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.5152 - Val Acc: 0.7684\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:06<00:00, 54.62it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.5030 - Val Acc: 0.7761\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:04<00:00, 66.96it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.4975 - Val Acc: 0.7462\n",
                        "      Evaluando en Test Set...\n",
                        "RESULTADO: accuracy                           0.91     18170 | macro avg       0.63      0.75      0.67     18170\n",
                        "\n",
                        "   >>> Entrenando: SOTA: All-MiniLM + MLP (lemmas_text)\n",
                        "Cargando Sentence Transformer: sentence-transformers/all-MiniLM-L6-v2\n",
                        "Estrategia: transformer | Dimensión Vectores: 384\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 329/329 [00:05<00:00, 62.05it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 37/37 [00:00<00:00, 60.75it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Entrenando SemanticMLP en cuda...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 1: 100%|██████████| 329/329 [00:01<00:00, 258.14it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 1 - Loss: 0.4725 - Val Acc: 0.8103\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 2: 100%|██████████| 329/329 [00:01<00:00, 257.97it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 2 - Loss: 0.4088 - Val Acc: 0.8188\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 3: 100%|██████████| 329/329 [00:01<00:00, 247.19it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 3 - Loss: 0.3740 - Val Acc: 0.8265\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 4: 100%|██████████| 329/329 [00:01<00:00, 233.92it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 4 - Loss: 0.3506 - Val Acc: 0.8256\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Ep 5: 100%|██████████| 329/329 [00:01<00:00, 231.71it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Ep 5 - Loss: 0.3271 - Val Acc: 0.8162\n",
                        "      Evaluando en Test Set...\n",
                        "Pre-computando embeddings (transformer)... esto puede tardar.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Batches: 100%|██████████| 568/568 [00:06<00:00, 90.02it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "RESULTADO: accuracy                           0.92     18170 | macro avg       0.68      0.82      0.74     18170\n",
                        "\n",
                        "   >>> Entrenando: SOTA: BGE-Small + MLP (lemmas_text)\n",
                        "Cargando Sentence Transformer: BAAI/bge-small-en-v1.5\n"
                    ]
                }
            ],
            "source": [
                "results_dl = []\n",
                "\n",
                "for col in input_columns:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\">>> PROCESANDO FEATURE: {col.upper()} <<<\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    X_full_col = df_full[col].astype(str) \n",
                "    \n",
                "    X_train_curr = X_full_col.loc[train_idx]\n",
                "    y_train_curr = y.loc[train_idx]\n",
                "    \n",
                "    X_test_curr = X_full_col.loc[test_idx]\n",
                "    y_test_curr = y.loc[test_idx]\n",
                "    \n",
                "    # Creamos DF temporal para facilitar el sampleo\n",
                "    train_df_temp = pd.DataFrame({'feature': X_train_curr, 'target': y_train_curr})\n",
                "    min_c = train_df_temp['target'].value_counts().min()\n",
                "    \n",
                "    print(f\"Balanceando Train a {min_c} muestras por clase...\")\n",
                "    \n",
                "    balanced_train = train_df_temp.groupby('target').apply(\n",
                "        lambda x: x.sample(min_c, random_state=42)\n",
                "    ).reset_index(drop=True)\n",
                "    \n",
                "    X_train_bal = balanced_train['feature']\n",
                "    y_train_bal = balanced_train['target']\n",
                "    \n",
                "    X_tr_final, X_val_final, y_tr_final, y_val_final = train_test_split(\n",
                "        X_train_bal, y_train_bal, test_size=0.1, random_state=42, stratify=y_train_bal\n",
                "    )\n",
                "    \n",
                "    print(f\"   Datos Finales DL -> Train: {len(X_tr_final)}, Val: {len(X_val_final)}\")\n",
                "    \n",
                "    for exp in experiments_config:\n",
                "        exp_id = f\"{exp['name']} ({col})\"\n",
                "        print(f\"\\n   >>> Entrenando: {exp_id}\")\n",
                "        \n",
                "        try:\n",
                "            # Instanciar\n",
                "            dl_man = AdvancedDLManager(strategy=exp['strategy'], model_name=exp['model'])\n",
                "            \n",
                "            # Entrenar W2V (si toca)\n",
                "            if exp['strategy'] == 'w2v':\n",
                "                # Entrenamos W2V con TODO el train balanceado (incluyendo val) para mejor vocabulario\n",
                "                dl_man.train_w2v(X_train_bal)\n",
                "            \n",
                "            history = dl_man.train(X_tr_final, y_tr_final, X_val_final, y_val_final, \n",
                "                                 epochs=5, batch_size=32)\n",
                "            \n",
                "            # Evaluar en Test Real\n",
                "            print(\"Evaluando en Test Set...\")\n",
                "            rep = dl_man.evaluate(X_test_curr, y_test_curr)\n",
                "            \n",
                "            # Guardar\n",
                "            results_dl.append({\n",
                "                'Feature': col,\n",
                "                'Model': exp['name'],\n",
                "                'Report_Raw': rep,\n",
                "                'History': history\n",
                "            })\n",
                "            \n",
                "            # Print rápido de resultados\n",
                "            lines = rep.split('\\n')\n",
                "            print(f\"RESULTADO: {lines[-4].strip()} | {lines[-3].strip()}\")\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"ERROR en {exp_id}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for res in results_dl:\n",
                "    print(f\"\\n[{res['Feature']}] {res['Model']}\")\n",
                "    lines = res['Report_Raw'].split('\\n')\n",
                "    print(f\"   Accuracy: {lines[-4].split()[1]}\")\n",
                "    print(f\"   Macro F1: {lines[-3].split()[-2]}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
