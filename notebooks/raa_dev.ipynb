{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Smart Urban System - NLP\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fase 1: Identificación y extracción de datos\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The autoreload extension is already loaded. To reload it, use:\n",
                        "  %reload_ext autoreload\n"
                    ]
                }
            ],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import sys\n",
                "from pathlib import Path\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Add src to path\n",
                "src_path = Path(\"../src\").resolve()\n",
                "if str(src_path) not in sys.path:\n",
                "    sys.path.append(str(src_path))\n",
                "\n",
                "from preprocessor import SmartUrbanPreprocessor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing NLP models...\n",
                        "Loading Stores Complaints...\n",
                        "Loading Financial Complaints...\n",
                        "Loading University Complaints...\n",
                        "Loading Amazon Reviews...\n",
                        "Loading News Sentiments...\n",
                        "Falling back to ISO-8859-1 encoding for news\n",
                        "Removing non-UTF-8 characters from news text\n",
                        "Removing non-UTF-8 characters from news sentiment\n",
                        "Converted news to UTF-8\n",
                        "stores: 81883 rows\n",
                        "financial: 162421 rows\n",
                        "university: 1005 rows\n",
                        "amazon: 30000 rows\n",
                        "news: 4846 rows\n"
                    ]
                }
            ],
            "source": [
                "processor = SmartUrbanPreprocessor()\n",
                "raw_data = processor.load_data()\n",
                "\n",
                "for source, df in raw_data.items():\n",
                "    print(f\"{source}: {len(df)} rows\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'stores': (81883, 24),\n",
                            " 'financial': (162421, 3),\n",
                            " 'university': (1005, 8),\n",
                            " 'amazon': (30000, 9),\n",
                            " 'news': (4846, 2)}"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "{k: v.shape for k, v in raw_data.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "stores = raw_data[\"stores\"]\n",
                "financial = raw_data[\"financial\"]\n",
                "university = raw_data[\"university\"]\n",
                "reviews = raw_data[\"amazon\"]\n",
                "news = raw_data[\"news\"]\n",
                "\n",
                "dfs = {\n",
                "    \"stores\": stores,\n",
                "    \"financial\": financial,\n",
                "    \"university\": university,\n",
                "    \"reviews\": reviews,\n",
                "    \"news\": news,\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### 1.1 EDA\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'stores':       ID_EXP FECHA_INGRESO            FECHA_FIN      FECHA DE CIERRE  \\\n",
                            " 0  2022_3584    2022-01-03  2022-08-15 00:00:00  2022-08-15 00:00:00   \n",
                            " 1  2022_2645    2022-01-03  2022-03-29 00:00:00  2022-03-29 00:00:00   \n",
                            " \n",
                            "                TIPO_CONCILIACION ESTADO_PROCESAL  \\\n",
                            " 0  Turnada a Concil Person p/seg      Conciliada   \n",
                            " 1  Turnada a Concil Person p/seg   Desistimiento   \n",
                            " \n",
                            "                             PROVEEDOR                    NOMBRE_COMERCIAL  \\\n",
                            " 0  DIVERSIDAD PARA EL HOGAR, SA DE CV  DIVERSIDAD PARA EL HOGAR, SA DE CV   \n",
                            " 1                        PROMEDIO 100                        PROMEDIO 100   \n",
                            " \n",
                            "                                     GIRO  \\\n",
                            " 0                              MUEBLERÍA   \n",
                            " 1  ESCUELA DE EDUCACIÓN PRIMARIA PRIVADA   \n",
                            " \n",
                            "                                   SECTOR  ... COSTO BIEN SERVICIO  \\\n",
                            " 0                               MUEBLERO  ...               16878   \n",
                            " 1  ESCUELA DE EDUCACIÓN PRIMARIA PRIVADA  ...             51111.8   \n",
                            " \n",
                            "   MONTO RECLAMADO MONTO RECUPERADO          PROCEDIMIENTO BIEN O SERV  \\\n",
                            " 0         16878.0            22688  Conciliación personal        Bien   \n",
                            " 1             NaN              NaN  Conciliación personal    Servicio   \n",
                            " \n",
                            "    MEDIO INGRESO        TIPO PROD           MODALIDAD COMPRA MODALIDAD PAGO  \\\n",
                            " 0        Escrito   Producto nuevo  En establecimiento físico        Contado   \n",
                            " 1       Personal  Servicio normal  En establecimiento físico         Plazos   \n",
                            " \n",
                            "           PROB ESPECIAL  \n",
                            " 0  No problema especial  \n",
                            " 1  No problema especial  \n",
                            " \n",
                            " [2 rows x 24 columns],\n",
                            " 'financial':    Unnamed: 0      product                                          narrative\n",
                            " 0           0  credit_card  purchase order day shipping amount receive pro...\n",
                            " 1           1  credit_card  forwarded message date tue subject please inve...,\n",
                            " 'university':                             Genre  \\\n",
                            " 0  Academic Support and Resources   \n",
                            " 1  Academic Support and Resources   \n",
                            " \n",
                            "                                              Reports  Age   Gpa  Year  Count  \\\n",
                            " 0  The limited access to research databases and m...   27  2.18     2      1   \n",
                            " 1  I'm having trouble finding the course material...   23  3.11     2      1   \n",
                            " \n",
                            "   Gender Nationality  \n",
                            " 0      M       Egypt  \n",
                            " 1      F       Egypt  ,\n",
                            " 'reviews':    Unnamed: 0   review_id          product_id          reviewer_id  stars  \\\n",
                            " 0           0  de_0784695  product_de_0572654  reviewer_de_0645436      1   \n",
                            " 1           1  de_0759207  product_de_0567331  reviewer_de_0183703      1   \n",
                            " \n",
                            "                                          review_body  \\\n",
                            " 0  Leider, leider nach einmal waschen ausgebliche...   \n",
                            " 1  zunächst macht der Anker Halter einen soliden ...   \n",
                            " \n",
                            "                        review_title language product_category  \n",
                            " 0         Leider nicht zu empfehlen       de             home  \n",
                            " 1  Gummierung nach 6 Monaten kaputt       de         wireless  ,\n",
                            " 'news':   sentiment                                               text\n",
                            " 0   neutral  According to Gran , the company has no plans t...\n",
                            " 1   neutral  Technopolis plans to develop in stages an area...}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "{k: df.head(2) for k, df in dfs.items()}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'stores': ((81883, 24),\n",
                            "  ID_EXP                         object\n",
                            "  FECHA_INGRESO          datetime64[ns]\n",
                            "  FECHA_FIN                      object\n",
                            "  FECHA DE CIERRE                object\n",
                            "  TIPO_CONCILIACION              object\n",
                            "  ESTADO_PROCESAL                object\n",
                            "  PROVEEDOR                      object\n",
                            "  NOMBRE_COMERCIAL               object\n",
                            "  GIRO                           object\n",
                            "  SECTOR                         object\n",
                            "  ODECO                          object\n",
                            "  ESTADO_UA                      object\n",
                            "  TIPO_RECLAMACION               object\n",
                            "  MOTIVO_RECLAMACION             object\n",
                            "  COSTO BIEN SERVICIO            object\n",
                            "  MONTO RECLAMADO               float64\n",
                            "  MONTO RECUPERADO               object\n",
                            "  PROCEDIMIENTO                  object\n",
                            "  BIEN O SERV                    object\n",
                            "  MEDIO INGRESO                  object\n",
                            "  TIPO PROD                      object\n",
                            "  MODALIDAD COMPRA               object\n",
                            "  MODALIDAD PAGO                 object\n",
                            "  PROB ESPECIAL                  object\n",
                            "  dtype: object),\n",
                            " 'financial': ((162421, 3),\n",
                            "  Unnamed: 0     int64\n",
                            "  product       object\n",
                            "  narrative     object\n",
                            "  dtype: object),\n",
                            " 'university': ((1005, 8),\n",
                            "  Genre           object\n",
                            "  Reports         object\n",
                            "  Age              int64\n",
                            "  Gpa            float64\n",
                            "  Year             int64\n",
                            "  Count            int64\n",
                            "  Gender          object\n",
                            "  Nationality     object\n",
                            "  dtype: object),\n",
                            " 'amazon': ((30000, 9),\n",
                            "  Unnamed: 0           int64\n",
                            "  review_id           object\n",
                            "  product_id          object\n",
                            "  reviewer_id         object\n",
                            "  stars                int64\n",
                            "  review_body         object\n",
                            "  review_title        object\n",
                            "  language            object\n",
                            "  product_category    object\n",
                            "  dtype: object),\n",
                            " 'news': ((4846, 2),\n",
                            "  sentiment    object\n",
                            "  text         object\n",
                            "  dtype: object)}"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "{k: (df.shape, df.dtypes) for k, df in raw_data.items()}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2. Unificar\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(280155, 5)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>text</th>\n",
                            "      <th>source</th>\n",
                            "      <th>language</th>\n",
                            "      <th>sentiment_score</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>de_0784695</td>\n",
                            "      <td>Leider, leider nach einmal waschen ausgebliche...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>de</td>\n",
                            "      <td>bad</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>de_0759207</td>\n",
                            "      <td>zunächst macht der Anker Halter einen soliden ...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>de</td>\n",
                            "      <td>bad</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>de_0711785</td>\n",
                            "      <td>Siegel sowie Verpackung war beschädigt und war...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>de</td>\n",
                            "      <td>bad</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>de_0964430</td>\n",
                            "      <td>Habe dieses Produkt NIE erhalten und das Geld ...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>de</td>\n",
                            "      <td>bad</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>de_0474538</td>\n",
                            "      <td>Die Träger sind schnell abgerissen Reißverschl...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>de</td>\n",
                            "      <td>bad</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "           id                                               text  source  \\\n",
                            "0  de_0784695  Leider, leider nach einmal waschen ausgebliche...  amazon   \n",
                            "1  de_0759207  zunächst macht der Anker Halter einen soliden ...  amazon   \n",
                            "2  de_0711785  Siegel sowie Verpackung war beschädigt und war...  amazon   \n",
                            "3  de_0964430  Habe dieses Produkt NIE erhalten und das Geld ...  amazon   \n",
                            "4  de_0474538  Die Träger sind schnell abgerissen Reißverschl...  amazon   \n",
                            "\n",
                            "  language sentiment_score  \n",
                            "0       de             bad  \n",
                            "1       de             bad  \n",
                            "2       de             bad  \n",
                            "3       de             bad  \n",
                            "4       de             bad  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "id                 object\n",
                        "text               object\n",
                        "source             object\n",
                        "language           object\n",
                        "sentiment_score    object\n",
                        "dtype: object\n"
                    ]
                }
            ],
            "source": [
                "unified_df = processor.normalize(raw_data)\n",
                "print(unified_df.shape)\n",
                "display(unified_df.head(5))\n",
                "print(unified_df.dtypes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Count</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>id</th>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>text</th>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>source</th>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>language</th>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>sentiment_score</th>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                 Count\n",
                            "id                   0\n",
                            "text                 1\n",
                            "source               0\n",
                            "language             0\n",
                            "sentiment_score      0"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(280155, 5)\n",
                        "(280154, 5)\n",
                        "\n",
                        "- Column id: 192420 unique values\n",
                        "- Column text: 273270 unique values\n",
                        "- Column source: 5 unique values\n",
                        "\t- Values: ['amazon' 'stores' 'financial' 'university' 'news']\n",
                        "- Column language: 6 unique values\n",
                        "\t- Values: ['de' 'en' 'es' 'fr' 'ja' 'zh']\n",
                        "- Column sentiment_score: 3 unique values\n",
                        "\t- Values: ['bad' 'neutral' 'good']\n"
                    ]
                }
            ],
            "source": [
                "# Valores faltantes\n",
                "missing = unified_df.isnull().sum()\n",
                "missing_pct = (missing / len(unified_df) * 100).round(2)\n",
                "missing_df = pd.DataFrame({\n",
                "    'Count': missing,\n",
                "})\n",
                "display(missing_df)\n",
                "print(unified_df.shape)\n",
                "working_df = unified_df[unified_df['text'].notna()]\n",
                "print(working_df.shape)\n",
                "\n",
                "print(\"\")\n",
                "\n",
                "# Unique values\n",
                "categorical_cols = working_df.select_dtypes(include=['object']).columns\n",
                "for col in categorical_cols:  \n",
                "    unique_count = working_df[col].nunique()\n",
                "    print(f\"- Column {col}: {unique_count} unique values\")\n",
                "    if unique_count <= 10:\n",
                "        print(f\"\\t- Values: {working_df[col].unique()}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2. Limpieza y normalización textual\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing corpus with 280155 documents...\n",
                        "Filtering by language (en/es)...\n",
                        "Removed 20000 documents with unsupported languages\n",
                        "Removing duplicates...\n",
                        "Removed 6884 duplicate entries\n",
                        "Cleaning text...\n",
                        "Tokenizing and lemmatizing...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing: 100%|██████████| 253271/253271 [10:34<00:00, 399.38it/s]  \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing complete. Final corpus size: 253271 documents\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>id</th>\n",
                            "      <th>text</th>\n",
                            "      <th>source</th>\n",
                            "      <th>language</th>\n",
                            "      <th>sentiment_score</th>\n",
                            "      <th>clean_text</th>\n",
                            "      <th>tokens</th>\n",
                            "      <th>lemmas</th>\n",
                            "      <th>pos_tags</th>\n",
                            "      <th>entities</th>\n",
                            "      <th>lemmas_text</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>5000</th>\n",
                            "      <td>en_0199937</td>\n",
                            "      <td>These are AWFUL. They are see through, the fab...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>en</td>\n",
                            "      <td>bad</td>\n",
                            "      <td>these are awful they are see through the fabri...</td>\n",
                            "      <td>[these, are, awful, they, are, see, through, t...</td>\n",
                            "      <td>[these, be, awful, they, be, see, through, the...</td>\n",
                            "      <td>[DET, AUX, ADJ, PRON, AUX, VERB, ADP, DET, NOU...</td>\n",
                            "      <td>[{'text': 'don', 'label': 'PERSON', 'start': 2...</td>\n",
                            "      <td>these be awful they be see through the fabric ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5001</th>\n",
                            "      <td>en_0863335</td>\n",
                            "      <td>I bought 4 and NONE of them worked. Yes I used...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>en</td>\n",
                            "      <td>bad</td>\n",
                            "      <td>i bought 4 and none of them worked yes i used ...</td>\n",
                            "      <td>[i, bought, 4, and, none, of, them, worked, ye...</td>\n",
                            "      <td>[I, buy, 4, and, none, of, they, work, yes, I,...</td>\n",
                            "      <td>[PRON, VERB, NUM, CCONJ, NOUN, ADP, PRON, VERB...</td>\n",
                            "      <td>[{'text': '4', 'label': 'CARDINAL', 'start': 9...</td>\n",
                            "      <td>I buy 4 and none of they work yes I use new ba...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5002</th>\n",
                            "      <td>en_0565010</td>\n",
                            "      <td>On first use it didn't heat up and now it does...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>en</td>\n",
                            "      <td>bad</td>\n",
                            "      <td>on first use it didn't heat up and now it does...</td>\n",
                            "      <td>[on, first, use, it, did, n't, heat, up, and, ...</td>\n",
                            "      <td>[on, first, use, it, do, not, heat, up, and, n...</td>\n",
                            "      <td>[ADP, ADJ, NOUN, PRON, AUX, PART, VERB, ADP, C...</td>\n",
                            "      <td>[{'text': 'first', 'label': 'ORDINAL', 'start'...</td>\n",
                            "      <td>on first use it do not heat up and now it do n...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5003</th>\n",
                            "      <td>en_0963290</td>\n",
                            "      <td>You want an HONEST answer? I just returned fro...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>en</td>\n",
                            "      <td>bad</td>\n",
                            "      <td>you want an honest answer i just returned from...</td>\n",
                            "      <td>[you, want, an, honest, answer, i, just, retur...</td>\n",
                            "      <td>[you, want, an, honest, answer, I, just, retur...</td>\n",
                            "      <td>[PRON, VERB, DET, ADJ, NOUN, PRON, ADV, VERB, ...</td>\n",
                            "      <td>[{'text': 'first', 'label': 'ORDINAL', 'start'...</td>\n",
                            "      <td>you want an honest answer I just return from u...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5004</th>\n",
                            "      <td>en_0238156</td>\n",
                            "      <td>The glue works fine but the container is impos...</td>\n",
                            "      <td>amazon</td>\n",
                            "      <td>en</td>\n",
                            "      <td>bad</td>\n",
                            "      <td>the glue works fine but the container is impos...</td>\n",
                            "      <td>[the, glue, works, fine, but, the, container, ...</td>\n",
                            "      <td>[the, glue, work, fine, but, the, container, b...</td>\n",
                            "      <td>[DET, NOUN, VERB, ADV, CCONJ, DET, NOUN, AUX, ...</td>\n",
                            "      <td>[]</td>\n",
                            "      <td>the glue work fine but the container be imposs...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "              id                                               text  source  \\\n",
                            "5000  en_0199937  These are AWFUL. They are see through, the fab...  amazon   \n",
                            "5001  en_0863335  I bought 4 and NONE of them worked. Yes I used...  amazon   \n",
                            "5002  en_0565010  On first use it didn't heat up and now it does...  amazon   \n",
                            "5003  en_0963290  You want an HONEST answer? I just returned fro...  amazon   \n",
                            "5004  en_0238156  The glue works fine but the container is impos...  amazon   \n",
                            "\n",
                            "     language sentiment_score  \\\n",
                            "5000       en             bad   \n",
                            "5001       en             bad   \n",
                            "5002       en             bad   \n",
                            "5003       en             bad   \n",
                            "5004       en             bad   \n",
                            "\n",
                            "                                             clean_text  \\\n",
                            "5000  these are awful they are see through the fabri...   \n",
                            "5001  i bought 4 and none of them worked yes i used ...   \n",
                            "5002  on first use it didn't heat up and now it does...   \n",
                            "5003  you want an honest answer i just returned from...   \n",
                            "5004  the glue works fine but the container is impos...   \n",
                            "\n",
                            "                                                 tokens  \\\n",
                            "5000  [these, are, awful, they, are, see, through, t...   \n",
                            "5001  [i, bought, 4, and, none, of, them, worked, ye...   \n",
                            "5002  [on, first, use, it, did, n't, heat, up, and, ...   \n",
                            "5003  [you, want, an, honest, answer, i, just, retur...   \n",
                            "5004  [the, glue, works, fine, but, the, container, ...   \n",
                            "\n",
                            "                                                 lemmas  \\\n",
                            "5000  [these, be, awful, they, be, see, through, the...   \n",
                            "5001  [I, buy, 4, and, none, of, they, work, yes, I,...   \n",
                            "5002  [on, first, use, it, do, not, heat, up, and, n...   \n",
                            "5003  [you, want, an, honest, answer, I, just, retur...   \n",
                            "5004  [the, glue, work, fine, but, the, container, b...   \n",
                            "\n",
                            "                                               pos_tags  \\\n",
                            "5000  [DET, AUX, ADJ, PRON, AUX, VERB, ADP, DET, NOU...   \n",
                            "5001  [PRON, VERB, NUM, CCONJ, NOUN, ADP, PRON, VERB...   \n",
                            "5002  [ADP, ADJ, NOUN, PRON, AUX, PART, VERB, ADP, C...   \n",
                            "5003  [PRON, VERB, DET, ADJ, NOUN, PRON, ADV, VERB, ...   \n",
                            "5004  [DET, NOUN, VERB, ADV, CCONJ, DET, NOUN, AUX, ...   \n",
                            "\n",
                            "                                               entities  \\\n",
                            "5000  [{'text': 'don', 'label': 'PERSON', 'start': 2...   \n",
                            "5001  [{'text': '4', 'label': 'CARDINAL', 'start': 9...   \n",
                            "5002  [{'text': 'first', 'label': 'ORDINAL', 'start'...   \n",
                            "5003  [{'text': 'first', 'label': 'ORDINAL', 'start'...   \n",
                            "5004                                                 []   \n",
                            "\n",
                            "                                            lemmas_text  \n",
                            "5000  these be awful they be see through the fabric ...  \n",
                            "5001  I buy 4 and none of they work yes I use new ba...  \n",
                            "5002  on first use it do not heat up and now it do n...  \n",
                            "5003  you want an honest answer I just return from u...  \n",
                            "5004  the glue work fine but the container be imposs...  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "clean_df = processor.process_corpus(unified_df, apply_spell_correction=False)\n",
                "display(clean_df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1. Guardado\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Saved to ..\\data\\processed_corpus.csv\n"
                    ]
                }
            ],
            "source": [
                "output_path = Path(\"../data/processed_corpus.csv\")\n",
                "clean_df.to_csv(output_path, index=False)\n",
                "print(f\"Saved to {output_path}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2. Balanceado?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\otero\\AppData\\Local\\Temp\\ipykernel_5016\\1176955817.py:3: DtypeWarning: Columns (0,1,5,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
                        "  clean_df = pd.read_csv(\"../data/processed_corpus.csv\")\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "clean_df = pd.read_csv(\"../data/processed_corpus.csv\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Source counts:\n",
                        " source\n",
                        "financial     162421\n",
                        "stores         76001\n",
                        "amazon         10000\n",
                        "news            4838\n",
                        "university        11\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Source counts:\\n\", clean_df['source'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Total Unified Rows: 253271\n",
                        "Sentiment counts:\n",
                        " sentiment_score\n",
                        "bad        243037\n",
                        "good         5362\n",
                        "neutral      4872\n",
                        "Name: count, dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "print(\"Sentiment counts:\\n\", clean_df['sentiment_score'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Undersampling to 4872 samples per class\n",
                        "\n",
                        "Total Balanced Rows: 14616\n",
                        "Balanced sentiment counts:\n",
                        " sentiment_score\n",
                        "good       4872\n",
                        "neutral    4872\n",
                        "bad        4872\n",
                        "Name: count, dtype: int64\n",
                        "Saved to ..\\data\\processed_corpus_balanced.csv\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.utils import resample\n",
                "import pandas as pd\n",
                "\n",
                "# Separar por clase\n",
                "bad_df = clean_df[clean_df['sentiment_score'] == 'bad']\n",
                "good_df = clean_df[clean_df['sentiment_score'] == 'good']\n",
                "neutral_df = clean_df[clean_df['sentiment_score'] == 'neutral']\n",
                "\n",
                "# Tamaño de la clase minoritaria\n",
                "min_size = min(len(good_df), len(neutral_df), len(bad_df))\n",
                "print(f\"Undersampling to {min_size} samples per class\")\n",
                "\n",
                "# Submuestrear cada clase\n",
                "bad_downsampled = resample(bad_df, \n",
                "                           replace=False,\n",
                "                           n_samples=min_size,\n",
                "                           random_state=42)\n",
                "\n",
                "good_downsampled = resample(good_df,\n",
                "                            replace=False,\n",
                "                            n_samples=min_size,\n",
                "                            random_state=42)\n",
                "\n",
                "neutral_downsampled = resample(neutral_df,\n",
                "                               replace=False,\n",
                "                               n_samples=min_size,\n",
                "                               random_state=42)\n",
                "\n",
                "# Combinar y mezclar\n",
                "balanced_df = pd.concat([bad_downsampled, good_downsampled, neutral_downsampled])\n",
                "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
                "\n",
                "# Verificar\n",
                "print(f\"\\nTotal Balanced Rows: {len(balanced_df)}\")\n",
                "print(\"Balanced sentiment counts:\\n\", balanced_df['sentiment_score'].value_counts())\n",
                "\n",
                "# Guardar\n",
                "balanced_path = Path(\"../data/processed_corpus_balanced.csv\")\n",
                "balanced_df.to_csv(balanced_path, index=False)\n",
                "print(f\"Saved to {balanced_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
