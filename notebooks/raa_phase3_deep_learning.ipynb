{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fase 3b: Deep Learning Models (BiLSTM)\n",
                "\n",
                "En este notebook, usamos `Word2Vec` para entrenar embeddings y `BiLSTM` para la clasificación."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pathlib import Path\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "\n",
                "# Add src\n",
                "sys.path.append(os.path.abspath(\"../src\"))\n",
                "from dl_models import AdvancedDLManager"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_path = Path(\"../data/processed_corpus.csv\")\n",
                "df_full = pd.read_csv(data_path)\n",
                "df_full = df_full.dropna(subset=['clean_text', 'sentiment_score'])\n",
                "\n",
                "# Definimos columnas a probar\n",
                "input_columns = ['clean_text', 'lemmas_text']\n",
                "\n",
                "# Usamos clean_text solo para sacar los índices, luego usaremos la columna que toque\n",
                "X_indices = df_full['clean_text'] \n",
                "y = df_full['sentiment_score']\n",
                "\n",
                "# Test Set Intocable\n",
                "X_train_raw, X_test_real, y_train_raw, y_test_real = train_test_split(\n",
                "    X_indices, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "train_idx = X_train_raw.index\n",
                "test_idx = X_test_real.index\n",
                "\n",
                "print(f\"Indices fijados -> Train Total: {len(train_idx)}, Test Intocable: {len(test_idx)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Entrenamiento de modelos de deep learning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "experiments_config = [\n",
                "    {\n",
                "        'name': 'Baseline: Word2Vec + BiLSTM',\n",
                "        'strategy': 'w2v',\n",
                "        'model': None\n",
                "    },\n",
                "    {\n",
                "        'name': 'SOTA: All-MiniLM + MLP',\n",
                "        'strategy': 'transformer',\n",
                "        'model': 'sentence-transformers/all-MiniLM-L6-v2' \n",
                "    },\n",
                "    {\n",
                "        'name': 'SOTA: BGE-Small + MLP',\n",
                "        'strategy': 'transformer',\n",
                "        'model': 'BAAI/bge-small-en-v1.5'\n",
                "    },\n",
                "    {\n",
                "        'name': 'GenAI: Gemma-Embed + MLP',\n",
                "        'strategy': 'ollama',\n",
                "        'model': 'embeddinggemma:latest'\n",
                "    }\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_dl = []\n",
                "\n",
                "for col in input_columns:\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\">>> PROCESANDO FEATURE: {col.upper()} <<<\")\n",
                "    print(f\"{'='*60}\")\n",
                "    \n",
                "    X_full_col = df_full[col].astype(str) \n",
                "    \n",
                "    X_train_curr = X_full_col.loc[train_idx]\n",
                "    y_train_curr = y.loc[train_idx]\n",
                "    \n",
                "    X_test_curr = X_full_col.loc[test_idx]\n",
                "    y_test_curr = y.loc[test_idx]\n",
                "    \n",
                "    # Creamos DF temporal para facilitar el sampleo\n",
                "    train_df_temp = pd.DataFrame({'feature': X_train_curr, 'target': y_train_curr})\n",
                "    min_c = train_df_temp['target'].value_counts().min()\n",
                "    \n",
                "    print(f\"Balanceando Train a {min_c} muestras por clase...\")\n",
                "    \n",
                "    balanced_train = train_df_temp.groupby('target').apply(\n",
                "        lambda x: x.sample(min_c, random_state=42)\n",
                "    ).reset_index(drop=True)\n",
                "    \n",
                "    X_train_bal = balanced_train['feature']\n",
                "    y_train_bal = balanced_train['target']\n",
                "    \n",
                "    X_tr_final, X_val_final, y_tr_final, y_val_final = train_test_split(\n",
                "        X_train_bal, y_train_bal, test_size=0.1, random_state=42, stratify=y_train_bal\n",
                "    )\n",
                "    \n",
                "    print(f\"   Datos Finales DL -> Train: {len(X_tr_final)}, Val: {len(X_val_final)}\")\n",
                "    \n",
                "    for exp in experiments_config:\n",
                "        exp_id = f\"{exp['name']} ({col})\"\n",
                "        print(f\"\\n   >>> Entrenando: {exp_id}\")\n",
                "        \n",
                "        try:\n",
                "            # Instanciar\n",
                "            dl_man = AdvancedDLManager(strategy=exp['strategy'], model_name=exp['model'])\n",
                "            \n",
                "            # Entrenar W2V (si toca)\n",
                "            if exp['strategy'] == 'w2v':\n",
                "                # Entrenamos W2V con TODO el train balanceado (incluyendo val) para mejor vocabulario\n",
                "                dl_man.train_w2v(X_train_bal)\n",
                "            \n",
                "            # Entrenar Red Neuronal\n",
                "            history = dl_man.train(X_tr_final, y_tr_final, X_val_final, y_val_final, \n",
                "                                 epochs=5, batch_size=32)\n",
                "            \n",
                "            # Evaluar en Test Real\n",
                "            print(\"      Evaluando en Test Set...\")\n",
                "            rep = dl_man.evaluate(X_test_curr, y_test_curr)\n",
                "            \n",
                "            # Guardar\n",
                "            results_dl.append({\n",
                "                'Feature': col,\n",
                "                'Model': exp['name'],\n",
                "                'Report_Raw': rep,\n",
                "                'History': history\n",
                "            })\n",
                "            \n",
                "            # Print rápido de resultados\n",
                "            lines = rep.split('\\n')\n",
                "            print(f\"RESULTADO: {lines[-4].strip()} | {lines[-3].strip()}\")\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"ERROR en {exp_id}: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for res in results_dl:\n",
                "    print(f\"\\n[{res['Feature']}] {res['Model']}\")\n",
                "    lines = res['Report_Raw'].split('\\n')\n",
                "    print(f\"   Accuracy: {lines[-4].split()[1]}\")\n",
                "    print(f\"   Macro F1: {lines[-3].split()[-2]}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
